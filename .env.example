# =============================================================================
# PharmLoop Environment Variables
# =============================================================================
# Copy this file to .env and adjust values for your environment.
# These control runtime paths, hardware, and training logistics.
# Architecture hyperparameters live in code as named constants (not here).
# =============================================================================

# ---- Paths ----
# Root directory for raw and processed data files
PHARMLOOP_DATA_DIR=./data

# Directory for saving model checkpoints during training
PHARMLOOP_CHECKPOINT_DIR=./checkpoints

# Directory for training logs and metrics
PHARMLOOP_LOG_DIR=./logs

# ---- Hardware / Device ----
# PyTorch device: "cpu", "cuda", "cuda:0", "mps", etc.
PHARMLOOP_DEVICE=cpu

# Number of data-loader workers (0 = main process only)
PHARMLOOP_NUM_WORKERS=0

# ---- Training ----
# Batch size for training
PHARMLOOP_BATCH_SIZE=32

# Learning rate
PHARMLOOP_LEARNING_RATE=1e-3

# Number of training epochs
PHARMLOOP_EPOCHS=50

# Random seed for reproducibility (leave empty for no fixed seed)
PHARMLOOP_SEED=42

# ---- Runtime ----
# Logging level: DEBUG, INFO, WARNING, ERROR
PHARMLOOP_LOG_LEVEL=INFO
